{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Solver.ipynb","provenance":[{"file_id":"17rdCMjkJ_AWIZM0nOjIWphRCYDKxCkkH","timestamp":1637688594473},{"file_id":"19zhdAlVB4Xfz3NkarbyuxPcHkVSWiXFc","timestamp":1637688148309}],"authorship_tag":"ABX9TyMR4u76TEU8xBycwIMWux9U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"k1pEPKycUzvm"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B0LR9vG50Dsw"},"source":["# coding: utf-8\n","import pickle\n","import os\n","import time\n","import numpy as np\n","import pandas as pd\n","from sklearn import metrics\n","import datetime\n","import csv\n","import tqdm\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.preprocessing import LabelBinarizer\n","from torch.utils.tensorboard import SummaryWriter\n","from torch.autograd import Variable\n","\n","import model as Model\n","\n","\n","skip_files = set(['TRAIISZ128F42684BB', 'TRAONEQ128F42A8AB7', 'TRADRNH128E0784511', 'TRBGHEU128F92D778F',\n","                 'TRCHYIF128F1464CE7', 'TRCVDKQ128E0790C86', 'TREWVFM128F146816E', 'TREQRIV128F1468B08',\n","                 'TREUVBN128F1468AC9', 'TRDKNBI128F14682B0', 'TRFWOAG128F14B12CB', 'TRFIYAF128F14688A6',\n","                 'TRGYAEZ128F14A473F', 'TRIXPRK128F1468472', 'TRAQKCW128F9352A52', 'TRLAWQU128F1468AC8',\n","                 'TRMSPLW128F14A544A', 'TRLNGQT128F1468261', 'TROTUWC128F1468AB4', 'TRNDAXE128F934C50E',\n","                 'TRNHIBI128EF35F57D', 'TRMOREL128F1468AC4',  'TRPNFAG128F146825F', 'TRIXPOY128F14A46C7',\n","                 'TROCQVE128F1468AC6', 'TRPCXJI128F14688A8', 'TRQKRKL128F1468AAE', 'TRPKNDC128F145998B',\n","                 'TRRUHEH128F1468AAD', 'TRLUSKX128F14A4E50', 'TRMIRQA128F92F11F1', 'TRSRUXF128F1468784',\n","                 'TRTNQKQ128F931C74D',  'TRTTUYE128F4244068', 'TRUQZKD128F1468243', 'TRUINWL128F1468258',\n","                 'TRVRHOY128F14680BC', 'TRWVEYR128F1458A6F', 'TRVLISA128F1468960', 'TRYDUYU128F92F6BE0',\n","                 'TRYOLFS128F9308346', 'TRMVCVS128F1468256', 'TRZSPHR128F1468AAC', 'TRXBJBW128F92EBD96',\n","                 'TRYPGJX128F1468479', 'TRYNNNZ128F1468994', 'TRVDOVF128F92DC7F3', 'TRWUHZQ128F1451979',\n","                 'TRXMAVV128F146825C', 'TRYNMEX128F14A401D', 'TREGWSL128F92C9D42', 'TRJKZDA12903CFBA43',\n","                  'TRBGJIZ128F92E42BC', 'TRVWNOH128E0788B78', 'TRCGBRK128F146A901'])\n","\n","TAGS = ['genre---downtempo', 'genre---ambient', 'genre---rock', 'instrument---synthesizer', 'genre---atmospheric', 'genre---indie', 'instrument---electricpiano', 'genre---newage', 'instrument---strings', 'instrument---drums', 'instrument---drummachine', 'genre---techno', 'instrument---guitar', 'genre---alternative', 'genre---easylistening', 'genre---instrumentalpop', 'genre---chillout', 'genre---metal', 'mood/theme---happy', 'genre---lounge', 'genre---reggae', 'genre---popfolk', 'genre---orchestral', 'instrument---acousticguitar', 'genre---poprock', 'instrument---piano', 'genre---trance', 'genre---dance', 'instrument---electricguitar', 'genre---soundtrack', 'genre---house', 'genre---hiphop', 'genre---classical', 'mood/theme---energetic', 'genre---electronic', 'genre---world', 'genre---experimental', 'instrument---violin', 'genre---folk', 'mood/theme---emotional', 'instrument---voice', 'instrument---keyboard', 'genre---pop', 'instrument---bass', 'instrument---computer', 'mood/theme---film', 'genre---triphop', 'genre---jazz', 'genre---funk', 'mood/theme---relaxing']\n","\n","def read_file(tsv_file):\n","    tracks = {}\n","    with open(tsv_file) as fp:\n","        reader = csv.reader(fp, delimiter='\\t')\n","        next(reader, None)  # skip header\n","        for row in reader:\n","            track_id = row[0]\n","            tracks[track_id] = {\n","                'path': row[3].replace('.mp3', '.npy'),\n","                'tags': row[5:],\n","            }\n","    return tracks\n","\n","\n","\n","class Solver(object):\n","    def __init__(self, data_loader, config):\n","        # data loader\n","        self.data_loader = data_loader\n","        self.dataset = config.dataset\n","        self.data_path = config.data_path\n","        self.input_length = config.input_length\n","\n","        # training settings\n","        self.n_epochs = config.n_epochs\n","        self.lr = config.lr\n","        self.use_tensorboard = config.use_tensorboard\n","\n","        # model path and step size\n","        self.model_save_path = config.model_save_path\n","        self.model_load_path = config.model_load_path\n","        self.log_step = config.log_step\n","        self.batch_size = config.batch_size\n","        self.model_type = config.model_type\n","\n","        # cuda\n","        self.is_cuda = torch.cuda.is_available()\n","\n","        # Build model\n","        self.get_dataset()\n","        self.build_model()\n","\n","        # Tensorboard\n","        self.writer = SummaryWriter()\n","\n","    def get_dataset(self):\n","        if self.dataset == 'mtat':\n","            self.valid_list = np.load('./../split/mtat/valid.npy')\n","            self.binary = np.load('./../split/mtat/binary.npy')\n","        if self.dataset == 'msd':\n","            train_file = os.path.join('./../split/msd','filtered_list_train.cP')\n","            train_list = pickle.load(open(train_file,'rb'), encoding='bytes')\n","            val_set = train_list[201680:]\n","            self.valid_list = [value for value in val_set if value.decode() not in skip_files]\n","            id2tag_file = os.path.join('./../split/msd', 'msd_id_to_tag_vector.cP')\n","            self.id2tag = pickle.load(open(id2tag_file,'rb'), encoding='bytes')\n","        if self.dataset == 'jamendo':\n","            train_file = os.path.join('./../split/mtg-jamendo', 'autotagging_top50tags-validation.tsv')\n","            self.file_dict= read_file(train_file)\n","            self.valid_list= list(read_file(train_file).keys())\n","            self.mlb = LabelBinarizer().fit(TAGS)\n","\n","\n","\n","    def get_model(self):\n","        if self.model_type == 'fcn':\n","            return Model.FCN()\n","        elif self.model_type == 'musicnn':\n","            return Model.Musicnn(dataset=self.dataset)\n","        elif self.model_type == 'crnn':\n","            return Model.CRNN()\n","        elif self.model_type == 'sample':\n","            return Model.SampleCNN()\n","        elif self.model_type == 'se':\n","            return Model.SampleCNNSE()\n","        elif self.model_type == 'short':\n","            return Model.ShortChunkCNN()\n","        elif self.model_type == 'short_res':\n","            return Model.ShortChunkCNN_Res()\n","        elif self.model_type == 'attention':\n","            return Model.CNNSA()\n","        elif self.model_type == 'hcnn':\n","            return Model.HarmonicCNN()\n","\n","    def build_model(self):\n","        # model\n","        self.model = self.get_model()\n","\n","        # cuda\n","        if self.is_cuda:\n","            self.model.cuda()\n","\n","        # load pretrained model\n","        if len(self.model_load_path) > 1:\n","            self.load(self.model_load_path)\n","\n","        # optimizers\n","        self.optimizer = torch.optim.Adam(self.model.parameters(), self.lr, weight_decay=1e-4)\n","\n","    def load(self, filename):\n","        S = torch.load(filename)\n","        if 'spec.mel_scale.fb' in S.keys():\n","            self.model.spec.mel_scale.fb = S['spec.mel_scale.fb']\n","        self.model.load_state_dict(S)\n","\n","    def to_var(self, x):\n","        if torch.cuda.is_available():\n","            x = x.cuda()\n","        return Variable(x)\n","\n","    def get_loss_function(self):\n","        return nn.BCELoss()\n","\n","    def train(self):\n","        # Start training\n","        start_t = time.time()\n","        current_optimizer = 'adam'\n","        reconst_loss = self.get_loss_function()\n","        best_metric = 0\n","        drop_counter = 0\n","\n","        # Iterate\n","        for epoch in range(self.n_epochs):\n","            ctr = 0\n","            drop_counter += 1\n","            self.model = self.model.train()\n","            for x, y in self.data_loader:\n","                ctr += 1\n","                # Forward\n","                x = self.to_var(x)\n","                y = self.to_var(y)\n","                out = self.model(x)\n","\n","                # Backward\n","                loss = reconst_loss(out, y)\n","                self.optimizer.zero_grad()\n","                loss.backward()\n","                self.optimizer.step()\n","\n","                # Log\n","                self.print_log(epoch, ctr, loss, start_t)\n","            self.writer.add_scalar('Loss/train', loss.item(), epoch)\n","\n","            # validation\n","            best_metric = self.validation(best_metric, epoch)\n","\n","            # schedule optimizer\n","            current_optimizer, drop_counter = self.opt_schedule(current_optimizer, drop_counter)\n","\n","        print(\"[%s] Train finished. Elapsed: %s\"\n","                % (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n","                    datetime.timedelta(seconds=time.time() - start_t)))\n","\n","    def opt_schedule(self, current_optimizer, drop_counter):\n","        # adam to sgd\n","        if current_optimizer == 'adam' and drop_counter == 80:\n","            self.load(os.path.join(self.model_save_path, 'best_model.pth'))\n","            self.optimizer = torch.optim.SGD(self.model.parameters(), 0.001,\n","                                            momentum=0.9, weight_decay=0.0001,\n","                                            nesterov=True)\n","            current_optimizer = 'sgd_1'\n","            drop_counter = 0\n","            print('sgd 1e-3')\n","        # first drop\n","        if current_optimizer == 'sgd_1' and drop_counter == 20:\n","            self.load(os.path.join(self.model_save_path, 'best_model.pth'))\n","            for pg in self.optimizer.param_groups:\n","                pg['lr'] = 0.0001\n","            current_optimizer = 'sgd_2'\n","            drop_counter = 0\n","            print('sgd 1e-4')\n","        # second drop\n","        if current_optimizer == 'sgd_2' and drop_counter == 20:\n","            self.load(os.path.join(self.model_save_path, 'best_model.pth'))\n","            for pg in self.optimizer.param_groups:\n","                pg['lr'] = 0.00001\n","            current_optimizer = 'sgd_3'\n","            print('sgd 1e-5')\n","        return current_optimizer, drop_counter\n","\n","    def save(self, filename):\n","        model = self.model.state_dict()\n","        torch.save({'model': model}, filename)\n","\n","    def get_tensor(self, fn):\n","        # load audio\n","        if self.dataset == 'mtat':\n","            npy_path = os.path.join(self.data_path, 'mtat', 'npy', fn.split('/')[1][:-3]) + 'npy'\n","        elif self.dataset == 'msd':\n","            msid = fn.decode()\n","            filename = '{}/{}/{}/{}.npy'.format(msid[2], msid[3], msid[4], msid)\n","            npy_path = os.path.join(self.data_path, filename)\n","        elif self.dataset == 'jamendo':\n","            filename = self.file_dict[fn]['path']\n","            npy_path = os.path.join(self.data_path, filename)\n","        raw = np.load(npy_path, mmap_mode='r')\n","\n","        # split chunk\n","        length = len(raw)\n","        hop = (length - self.input_length) // self.batch_size\n","        x = torch.zeros(self.batch_size, self.input_length)\n","        for i in range(self.batch_size):\n","            x[i] = torch.Tensor(raw[i*hop:i*hop+self.input_length]).unsqueeze(0)\n","        return x\n","\n","    def get_auc(self, est_array, gt_array):\n","        roc_aucs  = metrics.roc_auc_score(gt_array, est_array, average='macro')\n","        pr_aucs = metrics.average_precision_score(gt_array, est_array, average='macro')\n","        print('roc_auc: %.4f' % roc_aucs)\n","        print('pr_auc: %.4f' % pr_aucs)\n","        return roc_aucs, pr_aucs\n","\n","    def print_log(self, epoch, ctr, loss, start_t):\n","        if (ctr) % self.log_step == 0:\n","            print(\"[%s] Epoch [%d/%d] Iter [%d/%d] train loss: %.4f Elapsed: %s\" %\n","                    (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n","                        epoch+1, self.n_epochs, ctr, len(self.data_loader), loss.item(),\n","                        datetime.timedelta(seconds=time.time()-start_t)))\n","\n","    def validation(self, best_metric, epoch):\n","        roc_auc, pr_auc, loss = self.get_validation_score(epoch)\n","        score = 1 - loss\n","        if score > best_metric:\n","            print('best model!')\n","            best_metric = score\n","            torch.save(self.model.state_dict(),\n","                       os.path.join(self.model_save_path, 'best_model.pth'))\n","        return best_metric\n","\n","\n","    def get_validation_score(self, epoch):\n","        self.model = self.model.eval()\n","        est_array = []\n","        gt_array = []\n","        losses = []\n","        reconst_loss = self.get_loss_function()\n","        index = 0\n","        for line in tqdm.tqdm(self.valid_list):\n","            if self.dataset == 'mtat':\n","                ix, fn = line.split('\\t')\n","            elif self.dataset == 'msd':\n","                fn = line\n","                if fn.decode() in skip_files:\n","                    continue\n","            elif self.dataset == 'jamendo':\n","                fn = line\n","\n","            # load and split\n","            x = self.get_tensor(fn)\n","\n","            # ground truth\n","            if self.dataset == 'mtat':\n","                ground_truth = self.binary[int(ix)]\n","            elif self.dataset == 'msd':\n","                ground_truth = self.id2tag[fn].flatten()\n","            elif self.dataset == 'jamendo':\n","                ground_truth = np.sum(self.mlb.transform(self.file_dict[fn]['tags']), axis=0)\n","\n","\n","            # forward\n","            x = self.to_var(x)\n","            y = torch.tensor([ground_truth.astype('float32') for i in range(self.batch_size)]).cuda()\n","            out = self.model(x)\n","            loss = reconst_loss(out, y)\n","            losses.append(float(loss.data))\n","            out = out.detach().cpu()\n","\n","            # estimate\n","            estimated = np.array(out).mean(axis=0)\n","            est_array.append(estimated)\n","\n","            gt_array.append(ground_truth)\n","            index += 1\n","\n","        est_array, gt_array = np.array(est_array), np.array(gt_array)\n","        loss = np.mean(losses)\n","        print('loss: %.4f' % loss)\n","\n","        roc_auc, pr_auc = self.get_auc(est_array, gt_array)\n","        self.writer.add_scalar('Loss/valid', loss, epoch)\n","        self.writer.add_scalar('AUC/ROC', roc_auc, epoch)\n","        self.writer.add_scalar('AUC/PR', pr_auc, epoch)\n","        return roc_auc, pr_auc, loss\n"],"execution_count":null,"outputs":[]}]}