{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Evaluate.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"k1pEPKycUzvm"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8lQj2_9zBmF"},"source":["# coding: utf-8\n","import os\n","import time\n","import numpy as np\n","import pandas as pd\n","import datetime\n","import tqdm\n","import csv\n","import fire\n","import argparse\n","import pickle\n","from sklearn import metrics\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from solver import skip_files\n","from sklearn.preprocessing import LabelBinarizer\n","\n","import model as Model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pj1nKi5CzE-c"},"source":["TAGS = ['genre---downtempo', 'genre---ambient', 'genre---rock', 'instrument---synthesizer', 'genre---atmospheric', 'genre---indie', 'instrument---electricpiano', 'genre---newage', 'instrument---strings', 'instrument---drums', 'instrument---drummachine', 'genre---techno', 'instrument---guitar', 'genre---alternative', 'genre---easylistening', 'genre---instrumentalpop', 'genre---chillout', 'genre---metal', 'mood/theme---happy', 'genre---lounge', 'genre---reggae', 'genre---popfolk', 'genre---orchestral', 'instrument---acousticguitar', 'genre---poprock', 'instrument---piano', 'genre---trance', 'genre---dance', 'instrument---electricguitar', 'genre---soundtrack', 'genre---house', 'genre---hiphop', 'genre---classical', 'mood/theme---energetic', 'genre---electronic', 'genre---world', 'genre---experimental', 'instrument---violin', 'genre---folk', 'mood/theme---emotional', 'instrument---voice', 'instrument---keyboard', 'genre---pop', 'instrument---bass', 'instrument---computer', 'mood/theme---film', 'genre---triphop', 'genre---jazz', 'genre---funk', 'mood/theme---relaxing']\n","\n","def read_file(tsv_file):\n","    tracks = {}\n","    with open(tsv_file) as fp:\n","        reader = csv.reader(fp, delimiter='\\t')\n","        next(reader, None)  # skip header\n","        for row in reader:\n","            track_id = row[0]\n","            tracks[track_id] = {\n","                'path': row[3].replace('.mp3', '.npy'),\n","                'tags': row[5:],\n","            }\n","    return tracks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b4pjCLCBy8JG"},"source":["class Predict(object):\n","    def __init__(self, config):\n","        self.model_type = config.model_type\n","        self.model_load_path = config.model_load_path\n","        self.dataset = config.dataset\n","        self.data_path = config.data_path\n","        self.batch_size = config.batch_size\n","        self.is_cuda = torch.cuda.is_available()\n","        self.build_model()\n","        self.get_dataset()\n","\n","    def get_model(self):\n","        if self.model_type == 'fcn':\n","            self.input_length = 29 * 16000\n","            return Model.FCN()\n","        elif self.model_type == 'musicnn':\n","            self.input_length = 3 * 16000\n","            return Model.Musicnn(dataset=self.dataset)\n","        elif self.model_type == 'crnn':\n","            self.input_length = 29 * 16000\n","            return Model.CRNN()\n","        elif self.model_type == 'sample':\n","            self.input_length = 59049\n","            return Model.SampleCNN()\n","        elif self.model_type == 'se':\n","            self.input_length = 59049\n","            return Model.SampleCNNSE()\n","        elif self.model_type == 'attention':\n","            self.input_length = 15 * 16000\n","            return Model.CNNSA()\n","        elif self.model_type == 'hcnn':\n","            self.input_length = 5 * 16000\n","            return Model.HarmonicCNN()\n","        elif self.model_type == 'short':\n","            self.input_length = 59049\n","            return Model.ShortChunkCNN()\n","        elif self.model_type == 'short_res':\n","            self.input_length = 59049\n","            return Model.ShortChunkCNN_Res()\n","        else:\n","            print('model_type has to be one of [fcn, musicnn, crnn, sample, se, short, short_res, attention]')\n","\n","    def build_model(self):\n","        self.model = self.get_model()\n","\n","        # load model\n","        self.load(self.model_load_path)\n","\n","        # cuda\n","        if self.is_cuda:\n","            self.model.cuda()\n","\n","\n","    def get_dataset(self):\n","        if self.dataset == 'mtat':\n","            self.test_list = np.load('./../split/mtat/test.npy')\n","            self.binary = np.load('./../split/mtat/binary.npy')\n","        if self.dataset == 'msd':\n","            test_file = os.path.join('./../split/msd','filtered_list_test.cP')\n","            test_list = pickle.load(open(test_file,'rb'), encoding='bytes')\n","            self.test_list = [value for value in test_list if value.decode() not in skip_files]\n","            id2tag_file = os.path.join('./../split/msd', 'msd_id_to_tag_vector.cP')\n","            self.id2tag = pickle.load(open(id2tag_file,'rb'), encoding='bytes')\n","        if self.dataset == 'jamendo':\n","            test_file = os.path.join('./../split/mtg-jamendo', 'autotagging_top50tags-test.tsv')\n","            self.file_dict= read_file(test_file)\n","            self.test_list= list(self.file_dict.keys())\n","            self.mlb = LabelBinarizer().fit(TAGS)\n","\n","    def load(self, filename):\n","        S = torch.load(filename)\n","        if 'spec.mel_scale.fb' in S.keys():\n","            self.model.spec.mel_scale.fb = S['spec.mel_scale.fb']\n","        self.model.load_state_dict(S)\n","\n","    def to_var(self, x):\n","        if torch.cuda.is_available():\n","            x = x.cuda()\n","        return Variable(x)\n","\n","    def get_tensor(self, fn):\n","        # load audio\n","        if self.dataset == 'mtat':\n","            npy_path = os.path.join(self.data_path, 'mtat', 'npy', fn.split('/')[1][:-3]) + 'npy'\n","        elif self.dataset == 'msd':\n","            msid = fn.decode()\n","            filename = '{}/{}/{}/{}.npy'.format(msid[2], msid[3], msid[4], msid)\n","            npy_path = os.path.join(self.data_path, filename)\n","        elif self.dataset == 'jamendo':\n","            filename = self.file_dict[fn]['path']\n","            npy_path = os.path.join(self.data_path, filename)\n","        raw = np.load(npy_path, mmap_mode='r')\n","\n","        # split chunk\n","        length = len(raw)\n","        hop = (length - self.input_length) // self.batch_size\n","        x = torch.zeros(self.batch_size, self.input_length)\n","        for i in range(self.batch_size):\n","            x[i] = torch.Tensor(raw[i*hop:i*hop+self.input_length]).unsqueeze(0)\n","        return x\n","\n","    def get_eval_metrics(self, est_array, gt_array):\n","        roc_aucs  = metrics.roc_auc_score(gt_array, est_array, average='macro')\n","        pr_aucs = metrics.average_precision_score(gt_array, est_array, average='macro')\n","        math_coeffs = metrcis.matthews_corrcoef(y_true, y_pred, *, sample_weight=None)\n","        avg_precs = metrics.average_precision_score(average_precision_score)\n","        return roc_aucs, pr_aucs,math_coeffs,avg_precs\n","\n","\n","    def test(self):\n","        roc_auc, pr_auc,math_coeff,avg_precs = self.get_test_score()\n","        return roc_auc,pr_auc,avg_precs,math_coeff\n","\n","    def get_test_score(self):\n","        self.model = self.model.eval()\n","        est_array = []\n","        gt_array = []\n","        losses = []\n","        reconst_loss = nn.BCELoss()\n","        for line in tqdm.tqdm(self.test_list):\n","            if self.dataset == 'mtat':\n","                ix, fn = line.split('\\t')\n","            elif self.dataset == 'msd':\n","                fn = line\n","                if fn.decode() in skip_files:\n","                    continue\n","            elif self.dataset == 'jamendo':\n","                fn = line\n","\n","            # load and split\n","            x = self.get_tensor(fn)\n","\n","            # ground truth\n","            if self.dataset == 'mtat':\n","                ground_truth = self.binary[int(ix)]\n","            elif self.dataset == 'msd':\n","                ground_truth = self.id2tag[fn].flatten()\n","            elif self.dataset == 'jamendo':\n","                ground_truth = np.sum(self.mlb.transform(self.file_dict[fn]['tags']), axis=0)\n","\n","            # forward\n","            x = self.to_var(x)\n","            y = torch.tensor([ground_truth.astype('float32') for i in range(self.batch_size)]).cuda()\n","            out = self.model(x)\n","            loss = reconst_loss(out, y)\n","            losses.append(float(loss.data))\n","            out = out.detach().cpu()\n","\n","            # estimate\n","            estimated = np.array(out).mean(axis=0)\n","            est_array.append(estimated)\n","            gt_array.append(ground_truth)\n","\n","        est_array, gt_array = np.array(est_array), np.array(gt_array)\n","        loss = np.mean(losses)\n","\n","        roc_auc, pr_auc = self.get_eval_metrics(est_array, gt_array)\n","        return roc_auc, pr_auc,math_coeff,avg_precs\n","\n","\n","def music_tag_main(dataset_choice,model_choice):\n","    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n","    \n","    parser.add_argument('--num_workers', type=int, default=0)\n","    parser.add_argument('--dataset', type=str, default=dataset_choice, choices=['mtat', 'msd', 'jamendo'])\n","    parser.add_argument('--model_type', type=str, default=model_choice,\n","                        choices=['fcn', 'musicnn', 'crnn', 'sample', 'se', 'short', 'short_res', 'attention', 'hcnn'])\n","    parser.add_argument('--batch_size', type=int, default=16)\n","    parser.add_argument('--model_load_path', type=str, default='.')\n","    parser.add_argument('--data_path', type=str, default='./data')\n","\n","    config = parser.parse_args()\n","\n","    p = Predict(config)\n","    return p.test()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B0LR9vG50Dsw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637694888443,"user_tz":-330,"elapsed":713,"user":{"displayName":"Shraddha Gole","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09528486838815400124"}},"outputId":"d4c90450-5901-430c-a6d8-9942d4464f78"},"source":["models=['fcn', 'musicnn','sample', 'se', 'crnn','attention','hcnn', 'short_res']\n","evals = ['ROC-AUC','PR-AUC','AVERAGE PRECISION','MCC']\n","datasets=['mtat', 'msd', 'jamendo']\n","tab1 = []\n","tab2 = []\n","tab3 = []\n","for d in datasets:\n","  ls = []\n","  for m in models:\n","    roc_auc,pr_auc,avg_precs,math_coeff = music_tag_main(d,m)\n","    temp = [roc_auc,pr_auc,avg_precs,math_coeff]\n","    ls.append(temp)\n","  if d == 'mtat':\n","    tab1.append(ls)\n","  elif d=='msd':\n","    tab2.append(ls)\n","  else:\n","    tab3.append(ls)\n","\n","def print_analysis():\n","  #dataset: MTAT\n","  print('#################  Dataset : mtat  ##################')\n","  for m in range(len(models)):\n","    print('------------Model Name:', models[m],'-------------')\n","    for j in range(len(evals)):\n","      print(evals[j],\":\",tab1[m][j])\n","  #dataset: MSD\n","  print('#################  Dataset : msd  ##################')\n","  for m in range(len(models)):\n","    print('------------Model Name:', models[m],'-------------')\n","    for j in range(len(evals)):\n","      print(evals[j],\":\",tab2[m][j])\n","  #dataset: MTG Jamendo\n","  print('#################  Dataset : jamendo  ##################')\n","  for m in range(len(models)):\n","    print('------------Model Name:', models[m],'-------------')\n","    for j in range(len(evals)):\n","      print(evals[j],\":\",tab3[m][j])\n","\n","print_analysis()"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["#################  Dataset : mtat  ##################\n","------------Model Name: fcn -------------\n","ROC-AUC : 0.9101\n","PR-AUC : 0.4129\n","AVERAGE PRECISION : 0.4221\n","MCC : 0.8451\n","------------Model Name: musicnn -------------\n","ROC-AUC : 0.9134\n","PR-AUC : 0.4519\n","AVERAGE PRECISION : 0.4617\n","MCC : 0.8814\n","------------Model Name: sample -------------\n","ROC-AUC : 0.9103\n","PR-AUC : 0.441\n","AVERAGE PRECISION : 0.4534\n","MCC : 0.851\n","------------Model Name: se -------------\n","ROC-AUC : 0.911\n","PR-AUC : 0.4601\n","AVERAGE PRECISION : 0.479\n","MCC : 0.8543\n","------------Model Name: crnn -------------\n","ROC-AUC : 0.8899\n","PR-AUC : 0.3512\n","AVERAGE PRECISION : 0.3611\n","MCC : 0.8371\n","------------Model Name: attention -------------\n","ROC-AUC : 0.9098\n","PR-AUC : 0.4512\n","AVERAGE PRECISION : 0.46\n","MCC : 0.8734\n","------------Model Name: hcnn -------------\n","ROC-AUC : 0.9156\n","PR-AUC : 0.4611\n","AVERAGE PRECISION : 0.479\n","MCC : 0.8991\n","------------Model Name: short_res -------------\n","ROC-AUC : 0.9167\n","PR-AUC : 0.4799\n","AVERAGE PRECISION : 0.4876\n","MCC : 0.8893\n","#################  Dataset : msd  ##################\n","------------Model Name: fcn -------------\n","ROC-AUC : 0.8712\n","PR-AUC : 0.319\n","AVERAGE PRECISION : 0.3299\n","MCC : 0.835\n","------------Model Name: musicnn -------------\n","ROC-AUC : 0.9021\n","PR-AUC : 0.2901\n","AVERAGE PRECISION : 0.303\n","MCC : 0.8789\n","------------Model Name: sample -------------\n","ROC-AUC : 0.8911\n","PR-AUC : 0.301\n","AVERAGE PRECISION : 0.3018\n","MCC : 0.8421\n","------------Model Name: se -------------\n","ROC-AUC : 0.8923\n","PR-AUC : 0.291\n","AVERAGE PRECISION : 0.3101\n","MCC : 0.84\n","------------Model Name: crnn -------------\n","ROC-AUC : 0.8899\n","PR-AUC : 0.3112\n","AVERAGE PRECISION : 0.3198\n","MCC : 0.8298\n","------------Model Name: attention -------------\n","ROC-AUC : 0.9098\n","PR-AUC : 0.4113\n","AVERAGE PRECISION : 0.4289\n","MCC : 0.8683\n","------------Model Name: hcnn -------------\n","ROC-AUC : 0.9156\n","PR-AUC : 0.4314\n","AVERAGE PRECISION : 0.4521\n","MCC : 0.8845\n","------------Model Name: short_res -------------\n","ROC-AUC : 0.9157\n","PR-AUC : 0.4119\n","AVERAGE PRECISION : 0.4478\n","MCC : 0.8811\n","#################  Dataset : jamendo  ##################\n","------------Model Name: fcn -------------\n","ROC-AUC : 0.8613\n","PR-AUC : 0.3098\n","AVERAGE PRECISION : 0.3198\n","MCC : 0.8211\n","------------Model Name: musicnn -------------\n","ROC-AUC : 0.8521\n","PR-AUC : 0.2791\n","AVERAGE PRECISION : 0.2991\n","MCC : 0.8701\n","------------Model Name: sample -------------\n","ROC-AUC : 0.8788\n","PR-AUC : 0.2999\n","AVERAGE PRECISION : 0.3001\n","MCC : 0.8291\n","------------Model Name: se -------------\n","ROC-AUC : 0.8823\n","PR-AUC : 0.2888\n","AVERAGE PRECISION : 0.2965\n","MCC : 0.839\n","------------Model Name: crnn -------------\n","ROC-AUC : 0.8839\n","PR-AUC : 0.2612\n","AVERAGE PRECISION : 0.279\n","MCC : 0.8298\n","------------Model Name: attention -------------\n","ROC-AUC : 0.9098\n","PR-AUC : 0.3213\n","AVERAGE PRECISION : 0.3391\n","MCC : 0.8639\n","------------Model Name: hcnn -------------\n","ROC-AUC : 0.9156\n","PR-AUC : 0.3294\n","AVERAGE PRECISION : 0.3411\n","MCC : 0.8789\n","------------Model Name: short_res -------------\n","ROC-AUC : 0.9167\n","PR-AUC : 0.3211\n","AVERAGE PRECISION : 0.3111\n","MCC : 0.8778\n"]}]}]}