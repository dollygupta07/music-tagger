{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Model.ipynb","provenance":[{"file_id":"1nMzy6cNc4sPWj0H5ThRMcqvV_WyHDf1y","timestamp":1637688626315},{"file_id":"17rdCMjkJ_AWIZM0nOjIWphRCYDKxCkkH","timestamp":1637688594473},{"file_id":"19zhdAlVB4Xfz3NkarbyuxPcHkVSWiXFc","timestamp":1637688148309}],"authorship_tag":"ABX9TyOctnJLHvC5Wg30eBxXPR0I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"k1pEPKycUzvm"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B0LR9vG50Dsw"},"source":["# coding: utf-8\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torchaudio\n","\n","from modules import Conv_1d, ResSE_1d, Conv_2d, Res_2d, Conv_V, Conv_H, HarmonicSTFT, Res_2d_mp\n","from attention_modules import BertConfig, BertEncoder, BertEmbeddings, BertPooler, PositionalEncoding\n","\n","\n","class FCN(nn.Module):\n","    '''\n","    Choi et al. 2016\n","    Automatic tagging using deep convolutional neural networks.\n","    Fully convolutional network.\n","    '''\n","    def __init__(self,\n","                sample_rate=16000,\n","                n_fft=512,\n","                f_min=0.0,\n","                f_max=8000.0,\n","                n_mels=96,\n","                n_class=50):\n","        super(FCN, self).__init__()\n","\n","        # Spectrogram\n","        self.spec = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate,\n","                                                         n_fft=n_fft,\n","                                                         f_min=f_min,\n","                                                         f_max=f_max,\n","                                                         n_mels=n_mels)\n","        self.to_db = torchaudio.transforms.AmplitudeToDB()\n","        self.spec_bn = nn.BatchNorm2d(1)\n","\n","        # FCN\n","        self.layer1 = Conv_2d(1, 64, pooling=(2,4))\n","        self.layer2 = Conv_2d(64, 128, pooling=(2,4))\n","        self.layer3 = Conv_2d(128, 128, pooling=(2,4))\n","        self.layer4 = Conv_2d(128, 128, pooling=(3,5))\n","        self.layer5 = Conv_2d(128, 64, pooling=(4,4))\n","\n","        # Dense\n","        self.dense = nn.Linear(64, n_class)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, x):\n","        # Spectrogram\n","        x = self.spec(x)\n","        x = self.to_db(x)\n","        x = x.unsqueeze(1)\n","        x = self.spec_bn(x)\n","\n","        # FCN\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.layer5(x)\n","\n","        # Dense\n","        x = x.view(x.size(0), -1)\n","        x = self.dropout(x)\n","        x = self.dense(x)\n","        x = nn.Sigmoid()(x)\n","\n","        return x\n","\n","\n","class Musicnn(nn.Module):\n","    '''\n","    Pons et al. 2017\n","    End-to-end learning for music audio tagging at scale.\n","    This is the updated implementation of the original paper. Referred to the Musicnn code.\n","    https://github.com/jordipons/musicnn\n","    '''\n","    def __init__(self,\n","                sample_rate=16000,\n","                n_fft=512,\n","                f_min=0.0,\n","                f_max=8000.0,\n","                n_mels=96,\n","                n_class=50,\n","                dataset='mtat'):\n","        super(Musicnn, self).__init__()\n","\n","        # Spectrogram\n","        self.spec = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate,\n","                                                         n_fft=n_fft,\n","                                                         f_min=f_min,\n","                                                         f_max=f_max,\n","                                                         n_mels=n_mels)\n","        self.to_db = torchaudio.transforms.AmplitudeToDB()\n","        self.spec_bn = nn.BatchNorm2d(1)\n","\n","        # Pons front-end\n","        m1 = Conv_V(1, 204, (int(0.7*96), 7))\n","        m2 = Conv_V(1, 204, (int(0.4*96), 7))\n","        m3 = Conv_H(1, 51, 129)\n","        m4 = Conv_H(1, 51, 65)\n","        m5 = Conv_H(1, 51, 33)\n","        self.layers = nn.ModuleList([m1, m2, m3, m4, m5])\n","\n","        # Pons back-end\n","        backend_channel= 512 if dataset=='msd' else 64\n","        self.layer1 = Conv_1d(561, backend_channel, 7, 1, 1)\n","        self.layer2 = Conv_1d(backend_channel, backend_channel, 7, 1, 1)\n","        self.layer3 = Conv_1d(backend_channel, backend_channel, 7, 1, 1)\n","\n","        # Dense\n","        dense_channel = 500 if dataset=='msd' else 200\n","        self.dense1 = nn.Linear((561+(backend_channel*3))*2, dense_channel)\n","        self.bn = nn.BatchNorm1d(dense_channel)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(0.5)\n","        self.dense2 = nn.Linear(dense_channel, n_class)\n","\n","    def forward(self, x):\n","        # Spectrogram\n","        x = self.spec(x)\n","        x = self.to_db(x)\n","        x = x.unsqueeze(1)\n","        x = self.spec_bn(x)\n","\n","        # Pons front-end\n","        out = []\n","        for layer in self.layers:\n","            out.append(layer(x))\n","        out = torch.cat(out, dim=1)\n","\n","        # Pons back-end\n","        length = out.size(2)\n","        res1 = self.layer1(out)\n","        res2 = self.layer2(res1) + res1\n","        res3 = self.layer3(res2) + res2\n","        out = torch.cat([out, res1, res2, res3], 1)\n","\n","        mp = nn.MaxPool1d(length)(out)\n","        avgp = nn.AvgPool1d(length)(out)\n","\n","        out = torch.cat([mp, avgp], dim=1)\n","        out = out.squeeze(2)\n","\n","        out = self.relu(self.bn(self.dense1(out)))\n","        out = self.dropout(out)\n","        out = self.dense2(out)\n","        out = nn.Sigmoid()(out)\n","\n","        return out\n","\n","\n","class CRNN(nn.Module):\n","    '''\n","    Choi et al. 2017\n","    Convolution recurrent neural networks for music classification.\n","    Feature extraction with CNN + temporal summary with RNN\n","    '''\n","    def __init__(self,\n","                sample_rate=16000,\n","                n_fft=512,\n","                f_min=0.0,\n","                f_max=8000.0,\n","                n_mels=96,\n","                n_class=50):\n","        super(CRNN, self).__init__()\n","\n","        # Spectrogram\n","        self.spec = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate,\n","                                                         n_fft=n_fft,\n","                                                         f_min=f_min,\n","                                                         f_max=f_max,\n","                                                         n_mels=n_mels)\n","        self.to_db = torchaudio.transforms.AmplitudeToDB()\n","        self.spec_bn = nn.BatchNorm2d(1)\n","\n","        # CNN\n","        self.layer1 = Conv_2d(1, 64, pooling=(2,2))\n","        self.layer2 = Conv_2d(64, 128, pooling=(3,3))\n","        self.layer3 = Conv_2d(128, 128, pooling=(4,4))\n","        self.layer4 = Conv_2d(128, 128, pooling=(4,4))\n","\n","        # RNN\n","        self.layer5 = nn.GRU(128, 32, 2, batch_first=True)\n","\n","        # Dense\n","        self.dropout = nn.Dropout(0.5)\n","        self.dense = nn.Linear(32, 50)\n","\n","    def forward(self, x):\n","        # Spectrogram\n","        x = self.spec(x)\n","        x = self.to_db(x)\n","        x = x.unsqueeze(1)\n","        x = self.spec_bn(x)\n","\n","        # CCN\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        # RNN\n","        x = x.squeeze(2)\n","        x = x.permute(0, 2, 1)\n","        x, _ = self.layer5(x)\n","        x = x[:, -1, :]\n","\n","        # Dense\n","        x = self.dropout(x)\n","        x = self.dense(x)\n","        x = nn.Sigmoid()(x)\n","\n","        return x\n","\n","\n","class SampleCNN(nn.Module):\n","    '''\n","    Lee et al. 2017\n","    Sample-level deep convolutional neural networks for music auto-tagging using raw waveforms.\n","    Sample-level CNN.\n","    '''\n","    def __init__(self,\n","                 n_class=50):\n","        super(SampleCNN, self).__init__()\n","        self.layer1 = Conv_1d(1, 128, shape=3, stride=3, pooling=1)\n","        self.layer2 = Conv_1d(128, 128, shape=3, stride=1, pooling=3)\n","        self.layer3 = Conv_1d(128, 128, shape=3, stride=1, pooling=3)\n","        self.layer4 = Conv_1d(128, 256, shape=3, stride=1, pooling=3)\n","        self.layer5 = Conv_1d(256, 256, shape=3, stride=1, pooling=3)\n","        self.layer6 = Conv_1d(256, 256, shape=3, stride=1, pooling=3)\n","        self.layer7 = Conv_1d(256, 256, shape=3, stride=1, pooling=3)\n","        self.layer8 = Conv_1d(256, 256, shape=3, stride=1, pooling=3)\n","        self.layer9 = Conv_1d(256, 256, shape=3, stride=1, pooling=3)\n","        self.layer10 = Conv_1d(256, 512, shape=3, stride=1, pooling=3)\n","        self.layer11 = Conv_1d(512, 512, shape=1, stride=1, pooling=1)\n","        self.dropout = nn.Dropout(0.5)\n","        self.dense = nn.Linear(512, n_class)\n","\n","    def forward(self, x):\n","        x = x.unsqueeze(1)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.layer5(x)\n","        x = self.layer6(x)\n","        x = self.layer7(x)\n","        x = self.layer8(x)\n","        x = self.layer9(x)\n","        x = self.layer10(x)\n","        x = self.layer11(x)\n","        x = x.squeeze(-1)\n","        x = self.dropout(x)\n","        x = self.dense(x)\n","        x = nn.Sigmoid()(x)\n","        return x\n","\n","\n","class SampleCNNSE(nn.Module):\n","    '''\n","    Kim et al. 2018\n","    Sample-level CNN architectures for music auto-tagging using raw waveforms.\n","    Sample-level CNN + residual connections + squeeze & excitation.\n","    '''\n","    def __init__(self,\n","                 n_class=50):\n","        super(SampleCNNSE, self).__init__()\n","        self.layer1 = ResSE_1d(1, 128, shape=3, stride=3, pooling=1)\n","        self.layer2 = ResSE_1d(128, 128, shape=3, stride=1, pooling=3)\n","        self.layer3 = ResSE_1d(128, 128, shape=3, stride=1, pooling=3)\n","        self.layer4 = ResSE_1d(128, 256, shape=3, stride=1, pooling=3)\n","        self.layer5 = ResSE_1d(256, 256, shape=3, stride=1, pooling=3)\n","        self.layer6 = ResSE_1d(256, 256, shape=3, stride=1, pooling=3)\n","        self.layer7 = ResSE_1d(256, 256, shape=3, stride=1, pooling=3)\n","        self.layer8 = ResSE_1d(256, 256, shape=3, stride=1, pooling=3)\n","        self.layer9 = ResSE_1d(256, 256, shape=3, stride=1, pooling=3)\n","        self.layer10 = ResSE_1d(256, 512, shape=3, stride=1, pooling=3)\n","        self.layer11 = ResSE_1d(512, 512, shape=1, stride=1, pooling=1)\n","        self.dropout = nn.Dropout(0.5)\n","        self.dense1 = nn.Linear(512, 512)\n","        self.bn = nn.BatchNorm1d(512)\n","        self.dense2 = nn.Linear(512, n_class)\n","\n","    def forward(self, x):\n","        x = x.unsqueeze(1)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.layer5(x)\n","        x = self.layer6(x)\n","        x = self.layer7(x)\n","        x = self.layer8(x)\n","        x = self.layer9(x)\n","        x = self.layer10(x)\n","        x = self.layer11(x)\n","        x = x.squeeze(-1)\n","        x = nn.ReLU()(self.bn(self.dense1(x)))\n","        x = self.dropout(x)\n","        x = self.dense2(x)\n","        x = nn.Sigmoid()(x)\n","        return x\n","\n","\n","class ShortChunkCNN(nn.Module):\n","    '''\n","    Short-chunk CNN architecture.\n","    So-called vgg-ish model with a small receptive field.\n","    Deeper layers, smaller pooling (2x2).\n","    '''\n","    def __init__(self,\n","                n_channels=128,\n","                sample_rate=16000,\n","                n_fft=512,\n","                f_min=0.0,\n","                f_max=8000.0,\n","                n_mels=128,\n","                n_class=50):\n","        super(ShortChunkCNN, self).__init__()\n","\n","        # Spectrogram\n","        self.spec = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate,\n","                                                         n_fft=n_fft,\n","                                                         f_min=f_min,\n","                                                         f_max=f_max,\n","                                                         n_mels=n_mels)\n","        self.to_db = torchaudio.transforms.AmplitudeToDB()\n","        self.spec_bn = nn.BatchNorm2d(1)\n","\n","        # CNN\n","        self.layer1 = Conv_2d(1, n_channels, pooling=2)\n","        self.layer2 = Conv_2d(n_channels, n_channels, pooling=2)\n","        self.layer3 = Conv_2d(n_channels, n_channels*2, pooling=2)\n","        self.layer4 = Conv_2d(n_channels*2, n_channels*2, pooling=2)\n","        self.layer5 = Conv_2d(n_channels*2, n_channels*2, pooling=2)\n","        self.layer6 = Conv_2d(n_channels*2, n_channels*2, pooling=2)\n","        self.layer7 = Conv_2d(n_channels*2, n_channels*4, pooling=2)\n","\n","        # Dense\n","        self.dense1 = nn.Linear(n_channels*4, n_channels*4)\n","        self.bn = nn.BatchNorm1d(n_channels*4)\n","        self.dense2 = nn.Linear(n_channels*4, n_class)\n","        self.dropout = nn.Dropout(0.5)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        # Spectrogram\n","        x = self.spec(x)\n","        x = self.to_db(x)\n","        x = x.unsqueeze(1)\n","        x = self.spec_bn(x)\n","\n","        # CNN\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.layer5(x)\n","        x = self.layer6(x)\n","        x = self.layer7(x)\n","        x = x.squeeze(2)\n","\n","        # Global Max Pooling\n","        if x.size(-1) != 1:\n","            x = nn.MaxPool1d(x.size(-1))(x)\n","        x = x.squeeze(2)\n","\n","        # Dense\n","        x = self.dense1(x)\n","        x = self.bn(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.dense2(x)\n","        x = nn.Sigmoid()(x)\n","\n","        return x\n","\n","\n","class ShortChunkCNN_Res(nn.Module):\n","    '''\n","    Short-chunk CNN architecture with residual connections.\n","    '''\n","    def __init__(self,\n","                n_channels=128,\n","                sample_rate=16000,\n","                n_fft=512,\n","                f_min=0.0,\n","                f_max=8000.0,\n","                n_mels=128,\n","                n_class=50):\n","        super(ShortChunkCNN_Res, self).__init__()\n","\n","        # Spectrogram\n","        self.spec = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate,\n","                                                         n_fft=n_fft,\n","                                                         f_min=f_min,\n","                                                         f_max=f_max,\n","                                                         n_mels=n_mels)\n","        self.to_db = torchaudio.transforms.AmplitudeToDB()\n","        self.spec_bn = nn.BatchNorm2d(1)\n","\n","        # CNN\n","        self.layer1 = Res_2d(1, n_channels, stride=2)\n","        self.layer2 = Res_2d(n_channels, n_channels, stride=2)\n","        self.layer3 = Res_2d(n_channels, n_channels*2, stride=2)\n","        self.layer4 = Res_2d(n_channels*2, n_channels*2, stride=2)\n","        self.layer5 = Res_2d(n_channels*2, n_channels*2, stride=2)\n","        self.layer6 = Res_2d(n_channels*2, n_channels*2, stride=2)\n","        self.layer7 = Res_2d(n_channels*2, n_channels*4, stride=2)\n","\n","        # Dense\n","        self.dense1 = nn.Linear(n_channels*4, n_channels*4)\n","        self.bn = nn.BatchNorm1d(n_channels*4)\n","        self.dense2 = nn.Linear(n_channels*4, n_class)\n","        self.dropout = nn.Dropout(0.5)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        # Spectrogram\n","        x = self.spec(x)\n","        x = self.to_db(x)\n","        x = x.unsqueeze(1)\n","        x = self.spec_bn(x)\n","\n","        # CNN\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.layer5(x)\n","        x = self.layer6(x)\n","        x = self.layer7(x)\n","        x = x.squeeze(2)\n","\n","        # Global Max Pooling\n","        if x.size(-1) != 1:\n","            x = nn.MaxPool1d(x.size(-1))(x)\n","        x = x.squeeze(2)\n","\n","        # Dense\n","        x = self.dense1(x)\n","        x = self.bn(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.dense2(x)\n","        x = nn.Sigmoid()(x)\n","\n","        return x\n","\n","\n","class CNNSA(nn.Module):\n","    '''\n","    Won et al. 2019\n","    Toward interpretable music tagging with self-attention.\n","    Feature extraction with CNN + temporal summary with Transformer encoder.\n","    '''\n","    def __init__(self,\n","                n_channels=128,\n","                sample_rate=16000,\n","                n_fft=512,\n","                f_min=0.0,\n","                f_max=8000.0,\n","                n_mels=128,\n","                n_class=50):\n","        super(CNNSA, self).__init__()\n","\n","        # Spectrogram\n","        self.spec = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate,\n","                                                         n_fft=n_fft,\n","                                                         f_min=f_min,\n","                                                         f_max=f_max,\n","                                                         n_mels=n_mels)\n","        self.to_db = torchaudio.transforms.AmplitudeToDB()\n","        self.spec_bn = nn.BatchNorm2d(1)\n","\n","        # CNN\n","        self.layer1 = Res_2d(1, n_channels, stride=2)\n","        self.layer2 = Res_2d(n_channels, n_channels, stride=2)\n","        self.layer3 = Res_2d(n_channels, n_channels*2, stride=2)\n","        self.layer4 = Res_2d(n_channels*2, n_channels*2, stride=(2, 1))\n","        self.layer5 = Res_2d(n_channels*2, n_channels*2, stride=(2, 1))\n","        self.layer6 = Res_2d(n_channels*2, n_channels*2, stride=(2, 1))\n","        self.layer7 = Res_2d(n_channels*2, n_channels*2, stride=(2, 1))\n","\n","        # Transformer encoder\n","        bert_config = BertConfig(vocab_size=256,\n","                                 hidden_size=256,\n","                                 num_hidden_layers=2,\n","                                 num_attention_heads=8,\n","                                 intermediate_size=1024,\n","                                 hidden_act=\"gelu\",\n","                                 hidden_dropout_prob=0.4,\n","                                 max_position_embeddings=700,\n","                                 attention_probs_dropout_prob=0.5)\n","        self.encoder = BertEncoder(bert_config)\n","        self.pooler = BertPooler(bert_config)\n","        self.vec_cls = self.get_cls(256)\n","\n","        # Dense\n","        self.dropout = nn.Dropout(0.5)\n","        self.dense = nn.Linear(256, n_class)\n","\n","    def get_cls(self, channel):\n","        np.random.seed(0)\n","        single_cls = torch.Tensor(np.random.random((1, channel)))\n","        vec_cls = torch.cat([single_cls for _ in range(64)], dim=0)\n","        vec_cls = vec_cls.unsqueeze(1)\n","        return vec_cls\n","\n","    def append_cls(self, x):\n","        batch, _, _ = x.size()\n","        part_vec_cls = self.vec_cls[:batch].clone()\n","        part_vec_cls = part_vec_cls.to(x.device)\n","        return torch.cat([part_vec_cls, x], dim=1)\n","\n","    def forward(self, x):\n","        # Spectrogram\n","        x = self.spec(x)\n","        x = self.to_db(x)\n","        x = x.unsqueeze(1)\n","        x = self.spec_bn(x)\n","\n","        # CNN\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.layer5(x)\n","        x = self.layer6(x)\n","        x = self.layer7(x)\n","        x = x.squeeze(2)\n","\n","        # Get [CLS] token\n","        x = x.permute(0, 2, 1)\n","        x = self.append_cls(x)\n","\n","        # Transformer encoder\n","        x = self.encoder(x)\n","        x = x[-1]\n","        x = self.pooler(x)\n","\n","        # Dense\n","        x = self.dropout(x)\n","        x = self.dense(x)\n","        x = nn.Sigmoid()(x)\n","\n","        return x\n","\n","\n","class HarmonicCNN(nn.Module):\n","    '''\n","    Won et al. 2020\n","    Data-driven harmonic filters for audio representation learning.\n","    Trainable harmonic band-pass filters, short-chunk CNN.\n","    '''\n","    def __init__(self,\n","                n_channels=128,\n","                sample_rate=16000,\n","                n_fft=512,\n","                f_min=0.0,\n","                f_max=8000.0,\n","                n_mels=128,\n","                n_class=50,\n","                n_harmonic=6,\n","                semitone_scale=2,\n","                learn_bw='only_Q'):\n","        super(HarmonicCNN, self).__init__()\n","\n","        # Harmonic STFT\n","        self.hstft = HarmonicSTFT(sample_rate=sample_rate,\n","                                  n_fft=n_fft,\n","                                  n_harmonic=n_harmonic,\n","                                  semitone_scale=semitone_scale,\n","                                  learn_bw=learn_bw)\n","        self.hstft_bn = nn.BatchNorm2d(n_harmonic)\n","\n","        # CNN\n","        self.layer1 = Conv_2d(n_harmonic, n_channels, pooling=2)\n","        self.layer2 = Res_2d_mp(n_channels, n_channels, pooling=2)\n","        self.layer3 = Res_2d_mp(n_channels, n_channels, pooling=2)\n","        self.layer4 = Res_2d_mp(n_channels, n_channels, pooling=2)\n","        self.layer5 = Conv_2d(n_channels, n_channels*2, pooling=2)\n","        self.layer6 = Res_2d_mp(n_channels*2, n_channels*2, pooling=(2,3))\n","        self.layer7 = Res_2d_mp(n_channels*2, n_channels*2, pooling=(2,3))\n","\n","        # Dense\n","        self.dense1 = nn.Linear(n_channels*2, n_channels*2)\n","        self.bn = nn.BatchNorm1d(n_channels*2)\n","        self.dense2 = nn.Linear(n_channels*2, n_class)\n","        self.dropout = nn.Dropout(0.5)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        # Spectrogram\n","        x = self.hstft_bn(self.hstft(x))\n","\n","        # CNN\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.layer5(x)\n","        x = self.layer6(x)\n","        x = self.layer7(x)\n","        x = x.squeeze(2)\n","\n","        # Global Max Pooling\n","        if x.size(-1) != 1:\n","            x = nn.MaxPool1d(x.size(-1))(x)\n","        x = x.squeeze(2)\n","\n","        # Dense\n","        x = self.dense1(x)\n","        x = self.bn(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.dense2(x)\n","        x = nn.Sigmoid()(x)\n","\n","        return x\n"],"execution_count":null,"outputs":[]}]}